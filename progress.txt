# MyCoach — Progress Log

## Completed

### Phase 0: Foundation

- [x] **Project scaffolding** (commit 96d7a07)
  - pyproject.toml with dependencies (fastapi, sqlalchemy, alembic, pydantic, etc.)
  - Dev dependencies (pytest, pytest-asyncio, httpx, ruff, mypy)
  - Full directory structure per PRD Section 4
  - .env.example with placeholder env vars

- [x] **config.py with Pydantic Settings** (commit ce47409)
  - All settings groups: app, database, Garmin, Claude API, email, scheduler
  - MYCOACH_ env prefix, .env file support
  - Updated .env.example to match config field names

- [x] **database.py + main.py + test infrastructure** (commit fc7294f)
  - `database.py`: async SQLAlchemy engine, async_sessionmaker, DeclarativeBase, `get_db` FastAPI dependency
  - `main.py`: FastAPI app factory with lifespan (auto-creates tables), `GET /api/system/status` health check
  - `tests/conftest.py`: in-memory SQLite test engine, dependency override, auto-setup/teardown, async httpx client
  - `tests/test_api/test_system.py`: health check test (passing)

- [x] **Alembic async migrations setup**
  - Initialized Alembic with async template (`alembic init -t async`)
  - `alembic/env.py`: imports `Base.metadata` from `mycoach.database`, reads DB URL from `mycoach.config.Settings` dynamically
  - `render_as_batch=True` for SQLite ALTER TABLE compatibility
  - `alembic.ini`: removed hardcoded URL (driven by app config)
  - Verified: `alembic upgrade head` and `alembic revision --autogenerate` both work

- [x] **SQLAlchemy ORM models + Alembic migration**
  - 12 models across 8 files in `src/mycoach/models/`:
    - `user.py`: `User` — profile, fitness level, goals
    - `data_source.py`: `DataSourceConfig` — per-source config, credentials, sync status
    - `sport_profile.py`: `SportProfile` — per-sport skill level, goals, preferences, benchmarks
    - `availability.py`: `WeeklyAvailability` — time slots per day for upcoming week
    - `health.py`: `DailyHealthSnapshot` — HR, HRV, sleep, Body Battery, stress, training metrics, VO2max
    - `activity.py`: `Activity` + `GymWorkoutDetail` — workouts with HR/training effect; Hevy CSV sets/reps/weight/RPE
    - `plan.py`: `WeeklyPlan` + `PlannedSession` — generated plans with mesocycle tracking, linked to activities
    - `coaching.py`: `CoachingInsight` + `MesocycleConfig` — daily briefings, post-workout analysis, training blocks
    - `prompt_log.py`: `PromptLog` — LLM call tracking (tokens, latency, cost, prompt/response)
  - `models/__init__.py` re-exports all models
  - `main.py` and `alembic/env.py` import models to register with Base.metadata
  - Alembic autogenerate migration created and verified
  - All tests pass, ruff clean, mypy clean

- [x] **Pydantic schemas/DTOs in `schemas/`**
  - 9 schema files covering all 12 ORM models:
    - `user.py`: `UserCreate`, `UserUpdate`, `UserRead` with EmailStr validation
    - `data_source.py`: `DataSourceConfigCreate/Update/Read`, `DataSourceStatus`
    - `sport_profile.py`: `SportProfileCreate/Update/Read` with skill level validation
    - `availability.py`: `AvailabilitySlot`, `WeeklyAvailabilityCreate/Read`
    - `health.py`: `DailyHealthSnapshotCreate/Read` with all biometric fields
    - `activity.py`: `ActivityCreate/Read`, `GymWorkoutDetailCreate/Read` with RPE validation (1-10)
    - `plan.py`: `WeeklyPlanCreate/Read`, `PlannedSessionCreate/Read` with nested sessions
    - `coaching.py`: `CoachingInsightCreate/Read`, `MesocycleConfigCreate/Update/Read`
    - `system.py`: `StatusResponse`
  - `schemas/__init__.py` re-exports all 22 public schemas
  - Added `email-validator>=2.0.0` dependency for `EmailStr`
  - Validation: regex patterns for enums (fitness_level, skill_level, phase, insight_type, set_type), Field constraints (ge/le for day_of_week, rpe)
  - `from_attributes=True` on all Read schemas for ORM compatibility
  - 26 tests in `tests/test_schemas.py` covering valid/invalid cases
  - All tests pass, ruff clean, mypy clean

### Phase 1: Data Sources (in progress)

- [x] **Data source plugin system + Hevy CSV import**
  - `sources/base.py`: Abstract `DataSource` interface with `authenticate()`, `fetch_and_import()`, and `ImportResult` dataclass
  - `sources/hevy/csv_parser.py`: Parses Hevy CSV exports into `HevyWorkout`/`HevySet` dataclasses
    - Unit conversion: lbs→kg, miles→meters
    - Validates required columns, set_index, RPE range (1-10), datetime formats
    - BOM stripping for Windows-exported CSVs
    - Groups CSV rows into workouts by (title, start_time)
  - `sources/hevy/mappers.py`: Imports parsed workouts into DB as `Activity` + `GymWorkoutDetail` records
    - Deduplication by (user_id, title, start_time, data_source)
    - Duration calculation from start/end times
  - `api/routes/sources.py`: `POST /api/sources/import/hevy` endpoint (file upload)
  - Router registered in `main.py`
  - Added B008 ignore to ruff config (standard FastAPI `Depends()` pattern)
  - 20 new tests in `tests/test_sources/test_hevy.py`: CSV parsing (11), DB import (5), API endpoint (4)
  - All 47 tests pass, ruff clean, mypy clean

- [x] **Health + Activities API endpoints**
  - `api/routes/health.py`: 3 endpoints
    - `GET /api/health/today` — today's health snapshot (404 if none)
    - `GET /api/health/{date}` — snapshot for a specific date
    - `GET /api/health/trends?days=N` — last N days of snapshots (default 30, max 365)
  - `api/routes/activities.py`: 2 endpoints
    - `GET /api/activities` — paginated list with optional `sport` filter, includes gym workout details for gym activities
    - `GET /api/activities/{id}` — single activity with gym details
  - `PaginatedActivities` response model with `items`, `total`, `page`, `per_page`
  - Gym workout details loaded via join query (ordered by set_index)
  - Both routers registered in `main.py`
  - 15 new tests: health endpoints (7), activities endpoints (8)
  - All 62 tests pass, ruff clean, mypy clean

- [x] **Garmin source (auth, client, fetcher, mappers)**
  - `sources/garmin/auth.py`: `GarminAuth` class for authentication via garth
    - Token persistence: saves/resumes tokens from disk (configurable `garmin_token_dir`)
    - Fallback: resumes from saved tokens first, falls back to email/password login
    - Robust re-auth on token expiration
  - `sources/garmin/client.py`: `GarminClient` wrapper around garminconnect library
    - Methods for all health endpoints: stats, HR, HRV, sleep, stress, Body Battery, training readiness/status, VO2 max, respiration, SpO2
    - `get_activities_by_date()` for activity fetching
  - `sources/garmin/mappers.py`: Maps raw Garmin JSON to ORM models
    - `map_health_snapshot()`: Builds `DailyHealthSnapshot` from 10+ API responses, handles missing data gracefully, stores raw JSON for debugging
    - `map_activity()`: Maps Garmin activities to `Activity` model with sport classification (swimming, gym, cardio, other)
    - `import_health_snapshot()`: DB import with date-based deduplication
    - `import_activities()`: DB import with Garmin activity ID deduplication
    - Sport classification map: `GARMIN_SPORT_MAP` covering swimming variants, strength, cardio types
  - `sources/garmin/source.py`: `GarminSource` implements `DataSource` interface
    - `fetch_and_import()`: Orchestrates day-by-day health fetch + activity range fetch
    - `_safe_call()`: Wraps each API call so partial data is still captured on individual failures
    - Default 7-day lookback, configurable via `since` parameter
  - `api/routes/sources.py`: `POST /api/sources/sync/garmin` endpoint
    - Query param `days` (1-90, default 7) controls lookback period
    - Returns `GarminSyncResponse` with activities_created/skipped, health_snapshots_created, errors
    - 503 on auth failure with descriptive message
  - Enabled `garminconnect>=0.2.0` and `garth>=0.4.0` dependencies in pyproject.toml
  - 17 new tests in `tests/test_sources/test_garmin.py`:
    - Health snapshot mapper (3): full data, stats only, empty stats
    - Activity mapper (4): swimming, gym, unknown type, missing fields
    - DB import health (2): new + duplicate skip
    - DB import activities (3): new, duplicate skip, missing ID
    - GarminSource integration (2): fetch_and_import with mock client, auth failure
    - API endpoint (3): sync success, auth failure (503), days param
  - All 79 tests pass, ruff clean, mypy clean

- [x] **Data merging logic (Garmin + Hevy by date/time overlap)**
  - `sources/merger.py`: `merge_garmin_hevy()` finds overlapping gym activities by time
    - Matches Hevy gym activities with Garmin gym activities using time overlap with 30-min tolerance
    - Copies Garmin HR/calories/training effect data onto the Hevy activity
    - Sets `data_source` to "merged" and stores `garmin_activity_id`
    - Deletes redundant Garmin activity (frees unique constraint before update)
    - Picks best overlap when multiple Garmin activities exist
    - Fills missing Hevy duration from Garmin data
    - Idempotent: already-merged activities are skipped
  - `MergeResult` dataclass tracks merged count and errors
  - `api/routes/sources.py`: Updated existing endpoints + new endpoint
    - `POST /api/sources/merge`: Manual merge trigger
    - `POST /api/sources/import/hevy`: Now auto-merges after Hevy import
    - `POST /api/sources/sync/garmin`: Now auto-merges after Garmin sync
    - Response models updated with `activities_merged` field
  - 10 new tests in `tests/test_sources/test_merger.py`:
    - Merge logic (8): overlapping merge, no overlap, non-gym sport, no double merge, time tolerance, best overlap selection, no Hevy activities, duration fill from Garmin
    - API endpoint (2): merge endpoint success, nothing to merge
  - All 89 tests pass, ruff clean, mypy clean

- [x] **`GET /api/sources/status` endpoint** (Phase 1 complete)
  - `api/routes/sources.py`: New `GET /api/sources/status` endpoint
    - Returns status for each known source type (garmin, hevy_csv)
    - Derives status from actual data in DB (health snapshots, activities)
    - `sync_status`: "ok" when data exists, "never" when no data imported yet
    - `last_sync_at`: timestamp of most recently created record per source
    - "merged" activities count toward both garmin and hevy_csv status
  - `SourcesStatusResponse` wrapper model with `sources: list[DataSourceStatus]`
  - Uses existing `DataSourceStatus` schema from `schemas/data_source.py`
  - 4 new tests in `tests/test_sources/test_sources_status.py`:
    - No data (both "never"), garmin health data, hevy activity data, merged counts for both
  - All 93 tests pass, ruff clean, mypy clean

### Phase 2: Coaching Core (in progress)

- [x] **LLM client, prompt builder, response parser, coaching engine, daily briefing**
  - Enabled `anthropic>=0.40.0` dependency in pyproject.toml
  - `coaching/llm_client.py`: `LLMClient` wrapper around Anthropic Python SDK
    - `LLMResponse` dataclass with content, model, token counts, latency, cost
    - Cost estimation based on model pricing (Sonnet for daily, Opus for weekly)
    - Configurable model selection via `daily_model`/`weekly_model` properties
  - `coaching/response_parser.py`: JSON→Pydantic validation
    - `_extract_json()`: Handles markdown code blocks, raw JSON, surrounding text
    - `DailyBriefingResponse` model: sleep assessment, recovery status, readiness verdict (go_hard/moderate/active_recovery/rest), workout adjustments, sleep recommendation, key metrics
    - `parse_response()`: Generic JSON extraction + Pydantic validation with clear error messages
  - `coaching/prompt_builder.py`: Context assembly + prompt formatting
    - Loads versioned templates from `prompts/v1/`
    - `_format_health()`, `_format_health_trends()`, `_format_activities()`: Human-readable context formatting
    - `build_daily_briefing_prompt()`: Assembles full user message from health/activity data
    - `snapshot_to_dict()`, `activity_to_dict()`: ORM→dict converters
  - `coaching/context.py`: DB queries for prompt context
    - `get_today_health()`: Today's health snapshot
    - `get_health_trends()`: Last N days (excluding today)
    - `get_recent_activities()`: Recent activities by date range
  - `coaching/engine.py`: `CoachingEngine` orchestrator
    - `generate_daily_briefing()`: Full pipeline — context gather → prompt build → LLM call → parse → store
    - Retry once on JSON parse failure with explicit JSON instruction
    - Duplicate check (one briefing per day)
    - Stores `CoachingInsight` in DB + logs `PromptLog` (success and failure)
  - `prompts/v1/system.txt`: Coaching persona prompt (direct, data-driven, progressive)
  - `prompts/v1/daily_briefing.txt`: Daily briefing template with structured JSON output schema
  - `api/routes/coaching.py`: 2 endpoints
    - `GET /api/coaching/today` — retrieve today's briefing (404 if none)
    - `POST /api/coaching/today/generate` — generate briefing via LLM (409 if exists, 502 on failure)
  - Router registered in `main.py`
  - 34 new tests in `tests/test_coaching/`:
    - `test_response_parser.py` (10): JSON extraction (4), parse validation (6)
    - `test_prompt_builder.py` (10): format helpers (5), system prompt (1), build prompt (2+2)
    - `test_context.py` (7): health today (2), health trends (2), activities (2+1)
    - `test_engine.py` (5): success, prompt logging, duplicate check, LLM failure logging, retry on bad JSON
    - `test_api.py` (3): GET existing, 404 when none, 409 on duplicate generate
  - All 127 tests pass, ruff clean, mypy clean

### Phase 3: Weekly Plans (in progress)

- [x] **Availability API endpoints**
  - `api/routes/availability.py`: Full CRUD for weekly availability slots
    - `POST /api/availability`: Set weekly availability (replaces existing slots for that week)
    - `GET /api/availability/next-week`: Get slots for upcoming week (auto-calculates next Monday)
    - `GET /api/availability/{week_start}`: Get slots for a specific week (by Monday date)
    - `PUT /api/availability/{slot_id}`: Update a single slot
    - `DELETE /api/availability/{slot_id}`: Delete a single slot
  - Validation: `week_start` must be a Monday (422 if not)
  - Idempotent POST: deletes existing slots for the week before inserting new ones
  - Router registered in `main.py`
  - 10 new tests in `tests/test_api/test_availability.py`:
    - Set availability (1), replaces existing (1), rejects non-Monday (1)
    - Get week (1), rejects non-Monday (1), empty result (1)
    - Update slot (1), not found (1)
    - Delete slot (1), not found (1)
  - All 137 tests pass, ruff clean, mypy clean

- [x] **Weekly plan generation engine + API endpoints**
  - `coaching/response_parser.py`: Added `WeeklyPlanResponse` + `WeeklyPlanSessionResponse` models
    - Validates summary, sessions list (min 1), day_of_week (0-6), sport, title, duration, details (dict), notes
  - `coaching/context.py`: Added `get_availability_for_week()` — fetches availability slots for a given week with day names
  - `coaching/prompt_builder.py`: Added `_format_availability()` and `build_weekly_plan_prompt()`
    - Formats availability slots, health trends, recent activities, mesocycle context into prompt
  - `prompts/v1/weekly_plan.txt`: Weekly plan generation template
    - Instructions for sport-specific session generation (gym exercises/sets/reps/RPE, swimming drills/intervals, padel drills)
    - Mesocycle-aware (deload week volume/intensity reduction)
    - JSON output schema with sessions array matching availability slots
  - `coaching/engine.py`: Added `generate_weekly_plan()` method
    - Full pipeline: gather context → build prompt → LLM call (weekly model, 8192 max tokens) → parse → store
    - Validates week_start is Monday, checks for existing active plan (no duplicates)
    - Requires availability slots (raises ValueError if none)
    - Retry once on JSON parse failure
    - Stores `WeeklyPlan` + `PlannedSession` records, logs `PromptLog`
    - Session details stored as JSON in `PlannedSession.details`
  - `api/routes/plans.py`: 4 endpoints
    - `POST /api/plans/generate?week_start=` — generate plan via LLM (409 if exists/no availability, 502 on failure)
    - `GET /api/plans/current` — active plan for current week (404 if none)
    - `GET /api/plans/{plan_id}` — specific plan with sessions
    - `GET /api/plans/{plan_id}/sessions` — list sessions for a plan
  - Router registered in `main.py`
  - 20 new tests in `tests/test_plans/`:
    - `test_engine.py` (7): success, prompt logging, duplicate check, no availability, non-Monday, LLM failure, JSON details
    - `test_api.py` (7): get by id, not found, sessions list, sessions not found, no current, generate no availability 409, generate non-Monday 409
    - `test_context.py` (3): returns slots, empty, filters by week
    - `test_prompt_builder.py` (3): format slots, empty slots, build full prompt
  - All 157 tests pass, ruff clean, mypy clean

- [x] **Mesocycle tracking API + context integration**
  - `api/routes/mesocycles.py`: Full CRUD for mesocycle configurations per sport
    - `POST /api/mesocycles`: Create mesocycle config (409 if sport already exists)
    - `GET /api/mesocycles`: List all mesocycle configs
    - `GET /api/mesocycles/{sport}`: Get config for a specific sport
    - `PUT /api/mesocycles/{sport}`: Partial update (current_week, phase, progression_rules)
    - `DELETE /api/mesocycles/{sport}`: Delete mesocycle for a sport
  - `coaching/context.py`: Added `get_mesocycle_context()` function
    - Builds human-readable mesocycle summary from all configured sports
    - Detects deload weeks (current_week >= block_length_weeks) and flags them
    - Includes progression rules when configured
    - Returns None when no mesocycles configured (falls back to general programming)
  - `coaching/engine.py`: Updated `generate_weekly_plan()` to fetch and pass mesocycle context
    - Mesocycle data now flows into weekly plan LLM prompts via `mesocycle_context` parameter
  - Router registered in `main.py`
  - 14 new tests in `tests/test_api/test_mesocycles.py`:
    - API endpoints (10): create, duplicate (409), list, list empty, get by sport, not found, update, update not found, delete, delete not found
    - Context function (4): no configs, single sport, deload week detection, multiple sports
  - All 171 tests pass, ruff clean, mypy clean

## Next Up

- [ ] Phase 3 continued: sport-specific coaching modules
- [ ] Phase 4: Post-workout analysis
